{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d28cfb-1679-415a-b391-2b07d1f04f95",
   "metadata": {},
   "source": [
    "# Adds calculated baselines (see recalculate_baselines.ipynb) to an existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d728868-715f-49b6-a039-46644dfe59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from janelia_core.dataprocessing.dataset import ROIDataset\n",
    "from janelia_core.fileio.data_handlers import NDArrayHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6e611-2528-40ac-adb0-efaa1f10def2",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c3162e-b842-4b85-98d4-41f8d111f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of excel file specifying where the data for each experiment is saved relative to the base folder\n",
    "\n",
    "ps = dict()\n",
    "\n",
    "ps['data_loc_file'] = r'Z:\\Exchange\\Will\\bishoplab\\projects\\keller_drive\\keller_vnc\\data\\EM_volume_experiment_data_locations.xlsx'\n",
    "\n",
    "# Additional parameters (constant for all datasets) specifying where the data is stored\n",
    "ps['base_folder'] =r'W:\\\\SV4'\n",
    "ps['dataset_folder'] = 'extracted'\n",
    "\n",
    "# Name of the group the recalculated baselines as for\n",
    "ps['group_name'] =  'brain_rois_1_5_5'\n",
    "\n",
    "# Relative folder holding all data (including the new baseline data) for this group of rois\n",
    "ps['file_folder'] = 'brain_rois_1_5_5'\n",
    "\n",
    "# Name of file holding baselines\n",
    "ps['baseline_filename'] = 'baseline_f_1001.h5'\n",
    "\n",
    "# TS data string to associate with the baselines\n",
    "ps['baseline_ts_data_str'] = 'bl_brain_rois_1_5_5_1001'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f12cdb-79c9-4349-8ae0-80e9cce80da6",
   "metadata": {},
   "source": [
    "## Read in file specifying location of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54227c4f-904f-4cc8-b8bb-642618c766bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_fcn(str):\n",
    "    return str.replace(\"'\", \"\")\n",
    "converters = {0:c_fcn, 1:c_fcn}\n",
    "\n",
    "data_locs = pd.read_excel(ps['data_loc_file'], header=1, usecols=[1, 2], converters=converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ca926-6c2d-470f-9849-c59c54d7e297",
   "metadata": {},
   "source": [
    "## Add baselines for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f25e42f-2257-4408-9e57-c410f12339b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = len(data_locs)\n",
    "for d_i in range(n_datasets):\n",
    "    \n",
    "    # Get relevant paths\n",
    "    data_main_folder = data_locs['Main folder'][d_i]\n",
    "    data_sub_folder = data_locs['Subfolder'][d_i]\n",
    "    \n",
    "    # Base save path - this is the one which holds the subfolders holding the flourescence and baseline data\n",
    "    base_save_dir =  Path(ps['base_folder']) / data_main_folder / data_sub_folder / Path(ps['dataset_folder'])\n",
    "    dataset_path = base_save_dir / 'dataset.pkl'\n",
    "    # Load the dataset\n",
    "    with open(dataset_path, 'rb') as f:\n",
    "        dataset = ROIDataset.from_dict(pickle.load(f))\n",
    "\n",
    "        dataset.roi_groups[ps['group_name']]['ts_labels'].append(ps['baseline_ts_data_str'])\n",
    "        # Get time stamps from some other existing data in this group\n",
    "        \n",
    "        ts = dataset.ts_data[dataset.roi_groups[ps['group_name']]['ts_labels'][0]]['ts']\n",
    "        new_ts_data_entry = {'ts': ts, 'vls': NDArrayHandler(base_save_dir/ps['file_folder'], ps['baseline_filename'] )}\n",
    "        dataset.ts_data[ps['baseline_ts_data_str']] = new_ts_data_entry\n",
    "        \n",
    "        # Save the dataset\n",
    "        save_file = base_save_dir / 'dataset_test.pkl'\n",
    "        with open(save_file, 'wb') as f:\n",
    "            pickle.dump(dataset.to_dict(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc69c70-2bb6-411f-88af-4bacc9ebd9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
