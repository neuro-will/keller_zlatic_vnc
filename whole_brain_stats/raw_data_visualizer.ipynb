{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook for visualizing movies of raw flouresence for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyqtgraph as pg\n",
    "import pyspark\n",
    "\n",
    "from janelia_core.fileio.exp_reader import find_images\n",
    "from janelia_core.dataprocessing.utils import get_processed_image_data\n",
    "\n",
    "from keller_zlatic_vnc.data_processing import generate_standard_id_for_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of excel file specifying where the data for each experiment is saved relative to the base folder\n",
    "data_loc_file = r'A:\\projects\\keller_vnc\\data\\experiment_data_locations.xlsx'\n",
    "\n",
    "# Additional parameters (constant for all datasets) specifying where the data is stored\n",
    "image_base_folder =r'K:\\\\SV4'\n",
    "image_processed_folder = 'Results\\\\WeightFused'\n",
    "image_ext = r'weightFused.TimeRegistration.templateSpace.klb'\n",
    "\n",
    "# Extension for image files \n",
    "img_file_ext = 'weightFused.TimeRegistration.templateSpace.klb'\n",
    "\n",
    "# Subject id for which we want to load data\n",
    "s_id = 'CW_17-11-27-L4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in excel file specifying location of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_fcn(str):\n",
    "    return str.replace(\"'\", \"\")\n",
    "converters = {0:c_fcn, 1:c_fcn}\n",
    "\n",
    "volume_locs = pd.read_excel(data_loc_file, header=1, usecols=[1, 2], converters=converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get subject ids for each volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_subjs = [generate_standard_id_for_volume(volume_locs.loc[i,'Main folder'], \n",
    "                                                       volume_locs.loc[i,'Subfolder'])  for i in volume_locs.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find images for the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ind = np.argwhere(np.asarray(volume_subjs) == s_id)[0][0]\n",
    "data_main_folder = volume_locs['Main folder'][d_ind]\n",
    "data_sub_folder = volume_locs['Subfolder'][d_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = Path(image_base_folder) / data_main_folder / data_sub_folder / image_processed_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for image files...\n",
      "Found 6269 images.\n"
     ]
    }
   ],
   "source": [
    "imgs = find_images(image_folder=base_data_dir, image_ext=img_file_ext, image_folder_depth=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setMaster('local[20]').setAll([\n",
    "    ('spark.executor.memory', '10g'), ('spark.driver.memory','400g'), ('spark.driver.maxResultSize', '300g')])\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick some images to view and wisualize movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inds = slice(115, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_imgs = np.stack(get_processed_image_data(imgs[img_inds], func=lambda x: np.max(x, axis=0), sc=sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsWindows.ImageWindow at 0x17379ba4708>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.image(read_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
