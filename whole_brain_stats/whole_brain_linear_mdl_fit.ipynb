{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for fitting linear models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from janelia_core.stats.regression import grouped_linear_regression_boot_strap\n",
    "from janelia_core.stats.regression import grouped_linear_regression_boot_strap_stats\n",
    "from janelia_core.utils.data_saving import append_ts\n",
    "\n",
    "from keller_zlatic_vnc.linear_modeling import format_whole_brain_annots_table\n",
    "from keller_zlatic_vnc.linear_modeling import one_hot_from_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = {}\n",
    "ps['data_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\whole_brain_stats'\n",
    "ps['data_file'] = r'dff_5_25_25_2019_10_22_10_58_11_107249.pkl'\n",
    "\n",
    "# Specify variables that we predict from\n",
    "ps['beh_before'] = ['Q', 'F', 'B']\n",
    "ps['beh_after'] = ['Q', 'F', 'B']\n",
    "ps['enc_beh_interactions'] = True\n",
    "ps['enc_subjects'] = True\n",
    "ps['closure'] = True # True if the only events we consider must start with a before_beh \n",
    "                     # behavior and end with an beh_after behavior\n",
    "    \n",
    "# How many bootstrap samples we use in each analysis\n",
    "ps['n_bs_smps'] = 1000\n",
    "\n",
    "ps['save_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\whole_brain_stats'\n",
    "ps['save_str'] = 'whole_brain_boot_strap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(ps['data_folder']) / Path(ps['data_file'])\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "event_annots = data['event_annots']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns we don't need in the event annotation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_annots = event_annots.drop(['Manipulation Start', \n",
    "                                  'Manipulation End',\n",
    "                                  'Time differ between end of PB from Stimulus ONSET',\n",
    "                                  'Time differ between start of PB from Stimulus ONSET',\n",
    "                                  'Time difference between start of SB from Stimus ONSET',\n",
    "                                  'Interval Time',\n",
    "                                  'Transtion Time'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the event annotation table so it is ready to be passed to one_hot_from_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_annots = format_whole_brain_annots_table(event_annots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce closure if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enforcing closure.\n"
     ]
    }
   ],
   "source": [
    "if ps['closure']:\n",
    "    print('Enforcing closure.')\n",
    "    before_closure = np.asarray([b in set(ps['beh_before']) for b in event_annots['beh_before']], \n",
    "                                dtype=bool)\n",
    "    after_closure = np.asarray([b in set(ps['beh_after']) for b in event_annots['beh_after']], \n",
    "                                dtype=bool)\n",
    "    closure = np.logical_and(before_closure, after_closure)\n",
    "    \n",
    "    event_annots = event_annots[closure]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of events that have no behaviors of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_ignore = np.asarray([b not in set(ps['beh_before']) for b in event_annots['beh_before']], \n",
    "                                dtype=bool)\n",
    "after_ignore = np.asarray([b not in set(ps['beh_after']) for b in event_annots['beh_after']], \n",
    "                                dtype=bool)\n",
    "\n",
    "ignore_rows = np.logical_and(before_ignore, after_ignore)\n",
    "\n",
    "event_annots = event_annots[np.logical_not(ignore_rows)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get groups of data (a group corresponds to each subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = event_annots['subject_id'].unique()\n",
    "g = np.zeros(len(event_annots))\n",
    "for u_i, u_id in enumerate(unique_ids):\n",
    "    g[event_annots['subject_id'] == u_id] = u_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get a one-hot encoding of variables we will fit too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data, one_hot_vars = one_hot_from_table(table=event_annots, beh_before=ps['beh_before'], beh_after=ps['beh_after'], \n",
    "                                                enc_subjects=ps['enc_subjects'], \n",
    "                                                enc_beh_interactions=ps['enc_beh_interactions'])\n",
    "\n",
    "# If we are not encoding subjects, we will include a mean in the regression, so we note that in the variable names\n",
    "if not ps['enc_subjects']:\n",
    "    one_hot_vars.append('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now perform regression, with a bootstrap, for all supervoxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_before = np.stack(event_annots['dff_before'].to_numpy())\n",
    "dff_after = np.stack(event_annots['dff_after'].to_numpy())\n",
    "\n",
    "n_supervoxels = dff_before.shape[1]\n",
    "\n",
    "par_data_before = [(dff_before[:, n_i], one_hot_data, g, ps['n_bs_smps'], not ps['enc_subjects']) \n",
    "                   for n_i in range(n_supervoxels)]\n",
    "\n",
    "par_data_after = [(dff_after[:, n_i], one_hot_data, g, ps['n_bs_smps'], not ps['enc_subjects']) \n",
    "                   for n_i in range(n_supervoxels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "before_bs_rs = [grouped_linear_regression_boot_strap(*args) for args in par_data_before]\n",
    "\n",
    "t1 = time.time()\n",
    "print('Computaton time for ' + str(n_supervoxels) + ' super voxels: ' + str(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "after_bs_rs = [grouped_linear_regression_boot_strap(*args) for args in par_data_after]\n",
    "\n",
    "t1 = time.time()\n",
    "print('Computaton time for ' + str(n_supervoxels) + ' super voxels: ' + str(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = {'ps': ps, 'one_hot_vars': one_hot_vars, 'before_bs_rs': before_bs_rs, 'after_bs_rs': after_bs_rs}\n",
    "\n",
    "save_name = append_ts(ps['save_str']) + '.pkl'\n",
    "save_path = Path(ps['save_folder']) / save_name\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(rs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
