{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for looking at raw images of datasets around events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyqtgraph as pg\n",
    "import pyspark\n",
    "\n",
    "from janelia_core.dataprocessing.dataset import ROIDataset\n",
    "from janelia_core.dataprocessing.utils import get_processed_image_data\n",
    "\n",
    "from keller_zlatic_vnc.data_processing import match_annotation_subject_to_volume_subject\n",
    "from keller_zlatic_vnc.data_processing import read_raw_transitions_from_excel\n",
    "from keller_zlatic_vnc.data_processing import recode_beh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pyspark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setMaster('local[20]').setAll([\n",
    "    ('spark.executor.memory', '10g'), ('spark.driver.memory','400g'), ('spark.driver.maxResultSize', '300g')])\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = dict()\n",
    "\n",
    "# Location of excel file specifying where the data for each experiment is saved relative to the base folder\n",
    "ps['data_loc_file'] = r'A:\\projects\\keller_vnc\\data\\experiment_data_locations.xlsx'\n",
    "\n",
    "# Location of excel file specifying transition information \n",
    "ps['trans_file'] = r'A:\\projects\\keller_vnc\\data\\extracted_dff_v2\\transition_list.xlsx'\n",
    "\n",
    "# Subfolder containing the dataset for each subject\n",
    "ps['dataset_folder'] = 'extracted'\n",
    "\n",
    "# Base folder where datasets are stored \n",
    "ps['dataset_base_folder'] =r'K:\\\\SV4'\n",
    "\n",
    "\n",
    "# Index of dataset we want to look at\n",
    "ps['dataset_index'] = 10\n",
    "\n",
    "# Index of event we want to look at\n",
    "ps['event_index'] = 0\n",
    "\n",
    "# Number of frames we visualize before an event\n",
    "ps['n_frames_before'] = 1\n",
    "ps['n_frames_after'] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in excel file specifying location of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_fcn(str):\n",
    "    return str.replace(\"'\", \"\")\n",
    "converters = {0:c_fcn, 1:c_fcn}\n",
    "\n",
    "data_locs = pd.read_excel(ps['data_loc_file'], header=1, usecols=[1, 2], converters=converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in transition information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = read_raw_transitions_from_excel(ps['trans_file'], adjust_frame_index=True)\n",
    "trans = recode_beh(trans, 'Beh Before')\n",
    "trans = recode_beh(trans, 'Beh After')\n",
    "unique_trans_subjs = trans['Smp ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset if there are annotations for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_main_folder = data_locs['Main folder'][ps['dataset_index']]\n",
    "data_sub_folder = data_locs['Subfolder'][ps['dataset_index']]\n",
    "\n",
    "match_ind = match_annotation_subject_to_volume_subject(data_main_folder, data_sub_folder, unique_trans_subjs)\n",
    "\n",
    "if match_ind is not None:\n",
    "    \n",
    "    dataset_path = (Path(ps['dataset_base_folder']) / data_main_folder / data_sub_folder / \n",
    "                        Path(ps['dataset_folder']) / '*.pkl')\n",
    "    dataset_file = glob.glob(str(dataset_path))[0]\n",
    "    \n",
    "    with open(dataset_file, 'rb') as f:\n",
    "        dataset = ROIDataset.from_dict(pickle.load(f))\n",
    "        \n",
    "    sample_id = unique_trans_subjs[match_ind]\n",
    "    event_rows = trans['Smp ID'] == sample_id\n",
    "    sample_events = trans[event_rows]\n",
    "    \n",
    "else:\n",
    "    print('No annotations for dataset.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get images around the event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frame = sample_events.iloc[ps['event_index']]['Manipulation Start'] - ps['n_frames_before']\n",
    "stop_frame = sample_events.iloc[ps['event_index']]['Manipulation End'] + ps['n_frames_after']\n",
    "req_frames = slice(start_frame, stop_frame+1)\n",
    "\n",
    "imgs = [d['file'] for d in dataset.ts_data['imgs']['vls'][req_frames]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_proj(img):\n",
    "    return np.max(img, 0)\n",
    "\n",
    "max_projs = np.asarray(get_processed_image_data(imgs, max_proj, sc=sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsWindows.ImageWindow at 0x1de9c65ddc8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.image(max_projs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
