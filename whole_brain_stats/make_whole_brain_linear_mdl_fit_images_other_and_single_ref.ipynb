{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to make p-value images from the results of whole_bain_linear_mdl_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import imageio\n",
    "\n",
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyqtgraph as pg\n",
    "import tifffile\n",
    "\n",
    "from janelia_core.dataprocessing.dataset import ROIDataset\n",
    "from janelia_core.utils.data_saving import append_ts\n",
    "from janelia_core.visualization.volume_visualization import make_z_plane_movie\n",
    "from janelia_core.visualization.custom_color_maps import generate_normalized_rgb_cmap\n",
    "from janelia_core.visualization.volume_visualization import make_rgb_z_plane_movie\n",
    "from janelia_core.visualization.image_generation import rgb_3d_max_project\n",
    "from janelia_core.visualization.volume_visualization import comb_movies\n",
    "from janelia_core.visualization.volume_visualization import visualize_rgb_max_project\n",
    "\n",
    "from keller_zlatic_vnc.visualization import gen_coef_p_vl_cmap\n",
    "from keller_zlatic_vnc.visualization import visualize_coef_p_vl_max_projs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = {}\n",
    "\n",
    "# Location of results of whole_brain_linear_mdl_fit\n",
    "ps['results_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\whole_brain_stats\\v4\\dff_1_5_5_with_ep'\n",
    "ps['results_file'] = 'prediction_dependence_ref_Q_cut_off_time_3_231_mt_A9_dff_1_5_5_with_ep.pkl' # Quiet reference\n",
    "\n",
    "# A string to add to saved file names\n",
    "ps['save_supp_str'] = 'test'\n",
    "\n",
    "# Specify type of images we generate\n",
    "ps['gen_coef_movies'] = False\n",
    "ps['gen_coef_tiffs'] =  False\n",
    "\n",
    "ps['gen_p_value_movies'] = False\n",
    "ps['gen_p_value_tiffs'] = False\n",
    "\n",
    "ps['gen_filtered_coef_movies'] = False\n",
    "ps['gen_filtered_coef_tiffs'] = False\n",
    "\n",
    "ps['gen_combined_movies'] =False\n",
    "ps['gen_combined_tiffs'] = False\n",
    "ps['gen_combined_projs'] = True\n",
    "\n",
    "ps['gen_uber_movies'] = False\n",
    "\n",
    "# Threshold p-values if we are making threshold images - we will make an image for each p-value\n",
    "ps['thresholds'] = [.05, .01, .001]\n",
    "\n",
    "# Specify percentiles we use for mapping min and max coef values to colors - value should be between 0 and 100\n",
    "ps['coef_clim_percs'] = [1, 99]\n",
    "\n",
    "# Specify fixed limits for coefficients; if provided coef_clim_percs is ignored.  None indicates this parameter is not used\n",
    "# and limits for coefficients are calculated based on coef_clim_percs. \n",
    "\n",
    "ps['coef_lims'] = None #[-1, 1]\n",
    "\n",
    "# Specify lower percentile we use for mapping p-values to colors - should be between 0 and 100; upper value\n",
    "ps['min_p_val_perc'] = 1\n",
    "\n",
    "# Specify p-value which is mapped to black\n",
    "ps['max_p_vl'] = .05\n",
    "\n",
    "\n",
    "# Specify percentiles we use for mapping min and max values to colors for mean image - values should be between 0 and 100\n",
    "ps['mean_img_clim_percs'] = [0.1, 99.9]\n",
    "\n",
    "# Specify where the original datasets are located - we use these for determining the position of the rois\n",
    "ps['data_loc_file'] = r'A:\\projects\\keller_vnc\\data\\experiment_data_locations.xlsx'\n",
    "ps['dataset_folder'] = 'extracted'\n",
    "ps['dataset_base_folder'] = r'K:\\\\SV4'\n",
    "ps['roi_group'] = 'rois_1_5_5'\n",
    "\n",
    "# Specify where we find overlay files\n",
    "ps['overlay_files'] = [r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\overlays\\horz_mean.png',\n",
    "                       r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\overlays\\cor_mean.png',\n",
    "                       r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\overlays\\sag_mean.png']\n",
    "\n",
    "# Specify where we save images\n",
    "ps['save_folder'] = ps['results_folder']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_file = Path(ps['results_folder']) / ps['results_file']\n",
    "with open(rs_file, 'rb') as f:\n",
    "    rs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_behs = list(rs['beh_stats'].keys())\n",
    "n_rois = len(rs['beh_stats'][test_behs[0]]['p_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlays = [imageio.imread(overlay_file) for overlay_file in ps['overlay_files']]\n",
    "for o_i, overlay in enumerate(overlays):\n",
    "    new_overlay = np.zeros_like(overlay)\n",
    "    nz_inds = np.argwhere(overlay[:,:,0] != 255)\n",
    "    for ind in nz_inds:\n",
    "        new_overlay[ind[0], ind[1], :] = 255 - overlay[ind[0], ind[1], :]\n",
    "        new_overlay[ind[0], ind[1], 3] = new_overlay[ind[0], ind[1], 0]\n",
    "    overlays[o_i] = new_overlay\n",
    "    \n",
    "overlays[0] = np.flipud(overlays[0]) # Horizontal\n",
    "overlays[1] = np.fliplr(overlays[1])[1:, 1:, :] # Coronal\n",
    "overlays[2] = np.fliplr(np.moveaxis(overlays[2], 0, 1))[1:, 1:, :] # Sagital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851, 86, 4)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlays[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 851, 509)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset\n",
    "\n",
    "Because the rois are in the same location for each dataset, we can just look at the first dataset to find the position of the rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset locations\n",
    "def c_fcn(str):\n",
    "    return str.replace(\"'\", \"\")\n",
    "converters = {0:c_fcn, 1:c_fcn}\n",
    "\n",
    "data_locs = pd.read_excel(ps['data_loc_file'], header=1, usecols=[1, 2], converters=converters)\n",
    "\n",
    "# Read in the first dataset\n",
    "dataset_path = (Path(ps['dataset_base_folder']) / data_locs['Main folder'][0] / data_locs['Subfolder'][0] / \n",
    "                    Path(ps['dataset_folder']) / '*.pkl')\n",
    "dataset_file = glob.glob(str(dataset_path))[0]\n",
    "\n",
    "with open(dataset_file, 'rb') as f:\n",
    "    dataset = ROIDataset.from_dict(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ROI locations for first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = dataset.roi_groups[ps['roi_group']]['rois']\n",
    "if len(rois) != n_rois:\n",
    "    raise(RuntimeError('Number of rois in dataset does not match number of rois statistics are calculated for.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_img = dataset.stats['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_clims(vls, perc):\n",
    "    if ps['coef_lims'] is not None:\n",
    "        print('Using fixed coeficient color limits.')\n",
    "        return ps['coef_lims']\n",
    "    else:\n",
    "        small_v = np.percentile(vls, perc[0])\n",
    "        large_v = np.percentile(vls, perc[1])\n",
    "        v = np.max([np.abs(small_v), np.abs(large_v)])\n",
    "        return [-v, v]\n",
    "\n",
    "def p_vl_clims(vls, perc):\n",
    "    small_v = np.percentile(vls, perc)\n",
    "    return [small_v, np.log10(ps['max_p_vl'])]\n",
    "\n",
    "def generate_norm_map():\n",
    "    base_map = matplotlib.cm.viridis\n",
    "    return generate_normalized_rgb_cmap(base_map, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder to save results into\n",
    "image_folder = Path(ps['results_file']).stem # Save images under a folder with the same name as the results\n",
    "\n",
    "if ps['coef_lims'] is not None:\n",
    "    extra_str = '_w_fixed_coef_lims'\n",
    "else:\n",
    "    extra_str = ''\n",
    "\n",
    "save_folder_path= Path(ps['save_folder']) / (image_folder + extra_str)\n",
    "\n",
    "#os.makedirs(save_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bbox([[0.125, 0.19266371971185325], [0.7450000000000001, 0.7973362802881467]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the mean image\n",
    "mn_image_path = save_folder_path / 'mean.tiff'\n",
    "\n",
    "imageio.mimwrite(mn_image_path, mn_img)\n",
    "\n",
    "mn_img_min_c_lim = np.percentile(mn_img,  ps['mean_img_clim_percs'][0])\n",
    "mn_img_max_c_lim = np.percentile(mn_img, ps['mean_img_clim_percs'][1])\n",
    "\n",
    "make_z_plane_movie(volume=mn_img, save_path= str(save_folder_path /  'mean.mp4'), \n",
    "                   cmap='gray', clim=(mn_img_min_c_lim, mn_img_max_c_lim),\n",
    "                   title = 'Mean Image', cbar_label='$F$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 1025, 3)\n",
      "d_x: 851\n",
      "d_y: 509\n",
      "d_z: 86\n",
      "Done with making images for variable: F\n",
      "(1025, 1025, 3)\n",
      "d_x: 851\n",
      "d_y: 509\n",
      "d_z: 86\n",
      "Done with making images for variable: P\n"
     ]
    }
   ],
   "source": [
    "im_shape = mn_img.shape\n",
    "\n",
    "n_vars = len(test_behs)\n",
    "\n",
    "coef_cmap = generate_norm_map()\n",
    "\n",
    "for v_i in range(n_vars):\n",
    "    var_name = test_behs[v_i]\n",
    "    \n",
    "    coefs_image = np.zeros(im_shape, dtype=np.float32) \n",
    "    p_vls_image = np.zeros(im_shape, dtype=np.float32) \n",
    "\n",
    "    coefs = rs['beh_stats'][var_name]['beta']\n",
    "    p_vls = rs['beh_stats'][var_name]['p_values']\n",
    "    log_p_vls = np.log10(p_vls)\n",
    "    \n",
    "    for r_i in range(n_rois):\n",
    "        cur_voxel_inds = rois[r_i].voxel_inds\n",
    "        \n",
    "        coefs_image[cur_voxel_inds] = coefs[r_i]\n",
    "        p_vls_image[cur_voxel_inds] = p_vls[r_i]\n",
    "                \n",
    "    if ps['gen_coef_movies'] or ps['gen_coef_tiffs'] or ps['gen_uber_movies']:\n",
    "        coef_file_name = var_name + '_' + ps['save_supp_str'] + '_coefs'\n",
    "\n",
    "        if ps['gen_coef_tiffs']:\n",
    "            tifffile.imwrite(save_folder_path / (coef_file_name + '.tiff'), coefs_image, compress=6)\n",
    " \n",
    "        if ps['gen_coef_movies'] or ps['gen_uber_movies']:\n",
    "            coef_movie_path = str(save_folder_path / (coef_file_name + '.mp4'))\n",
    "            coef_movie_ax_pos = make_z_plane_movie(volume=coefs_image, save_path=coef_movie_path, \n",
    "                               cmap=coef_cmap, clim=coef_clims(coefs, ps['coef_clim_percs']), \n",
    "                               title = var_name, cbar_label='${\\Delta F}/{F}$',\n",
    "                               one_index_z_plane=True)\n",
    "        \n",
    "    if ps['gen_p_value_movies'] or ps['gen_p_value_tiffs'] or ps['gen_uber_movies']:\n",
    "        p_vl_file_name = var_name + '_' + ps['save_supp_str'] + '_p_vls'\n",
    "        \n",
    "        if ps['gen_p_value_tiffs']:\n",
    "            tifffile.imwrite(save_folder_path / (p_vl_file_name + '.tiff'), p_vls_image, compress=6)\n",
    "       \n",
    "        if ps['gen_p_value_movies'] or ps['gen_uber_movies']:\n",
    "            log_p_vls_image = np.log10(p_vls_image)\n",
    "            log_p_vls_image[p_vls_image == 0] = 0\n",
    "        \n",
    "            p_vl_movie_path = str(save_folder_path / (p_vl_file_name + '.mp4'))\n",
    "            make_z_plane_movie(volume=log_p_vls_image, save_path=p_vl_movie_path, \n",
    "                               cmap='magma_r', clim=p_vl_clims(log_p_vls, ps['min_p_val_perc']), \n",
    "                               title = var_name, cbar_label='$\\log_{10}(p)$',\n",
    "                               one_index_z_plane=True)\n",
    "    \n",
    "    if ps['gen_filtered_coef_movies'] or ps['gen_filtered_coef_tiffs']:\n",
    "        for th in ps['thresholds']:\n",
    "            filtered_coef_file_name = var_name + '_' + ps['save_supp_str'] + '_coefs_p_th_' + str(th)\n",
    "            \n",
    "            coefs_image_th = copy.deepcopy(coefs_image)\n",
    "            \n",
    "            coefs_image_th[p_vls_image > th] = 0\n",
    "            \n",
    "            if ps['gen_filtered_coef_tiffs']:\n",
    "                tifffile.imwrite(save_folder_path / (filtered_coef_file_name + '.tiff'), coefs_image_th, compress=6)\n",
    "     \n",
    "            if ps['gen_filtered_coef_movies']:\n",
    "                ax_pos = make_z_plane_movie(volume=coefs_image_th, save_path=str(save_folder_path / (filtered_coef_file_name + '.mp4')), \n",
    "                                   cmap=coef_cmap, clim=coef_clims(coefs, ps['coef_clim_percs']),\n",
    "                                   title = var_name + '$, p \\leq$' + str(th), cbar_label='${\\Delta F}/{F}$')\n",
    "            \n",
    "    if ps['gen_combined_movies'] or ps['gen_combined_tiffs'] or ps['gen_combined_projs'] or ps['gen_uber_movies']:\n",
    "        combined_file_name = var_name + '_' + ps['save_supp_str'] + '_combined'\n",
    "        \n",
    "        \n",
    "        \n",
    "        log_p_vls_image = np.log10(p_vls_image)\n",
    "        log_p_vls_image[p_vls_image == 0] = 0\n",
    "        \n",
    "        # Generate combined color map\n",
    "        combined_cmap = gen_coef_p_vl_cmap(coef_cmap=coef_cmap, \n",
    "                                           positive_clim=coef_clims(coefs, ps['coef_clim_percs'])[1],\n",
    "                                           plims=p_vl_clims(log_p_vls, ps['min_p_val_perc']))\n",
    "\n",
    "        # Make RGB volumes \n",
    "        combined_vol = combined_cmap[coefs_image, log_p_vls_image]\n",
    "        \n",
    "        combined_vol_uint8 = (combined_vol*255).astype(np.uint8)\n",
    "        \n",
    "        n_z_planes = coefs_image.shape[0]\n",
    "        combined_planes = [np.squeeze(combined_vol[z, :,:,:]) for z in range(n_z_planes)]\n",
    "        \n",
    "        # Save tiff stacks of RGB volumes\n",
    "        if ps['gen_combined_tiffs']:\n",
    "            tifffile.imwrite(save_folder_path / (combined_file_name + '.tiff'), combined_vol_uint8, compress=6)\n",
    "\n",
    "            # Save colormaps for combined tiffs\n",
    "            combined_cmap_file = save_folder_path / (combined_file_name + '_cmap.pkl')\n",
    "            with open(combined_cmap_file, 'wb') as f:\n",
    "                pickle.dump(combined_cmap.to_dict(), f)\n",
    "\n",
    "        # Make videos of RGB volumes\n",
    "        if ps['gen_combined_movies'] or ps['gen_uber_movies']:\n",
    "            comb_movie_path = str(save_folder_path / (combined_file_name + '.mp4'))\n",
    "            make_rgb_z_plane_movie(z_imgs=combined_planes, \n",
    "                                   save_path=comb_movie_path,\n",
    "                                   cmap=combined_cmap, \n",
    "                                   title=var_name,\n",
    "                                   cmap_param_vls=(None, np.arange(combined_cmap.param_vl_ranges[1][1], \n",
    "                                                                   combined_cmap.param_vl_ranges[1][0], .01)),\n",
    "                                   cmap_param_strs = ['coef vl ($\\Delta F / F$)', '$\\log(p)$'],\n",
    "                                   one_index_z_plane=True, \n",
    "                                   ax_position=coef_movie_ax_pos)\n",
    "                                           \n",
    "        if ps['gen_combined_projs']:\n",
    "            \n",
    "            visualize_coef_p_vl_max_projs(vol=np.moveaxis(combined_vol, 0, 2), dim_m=np.asarray([1, 1, 5]), \n",
    "                                          cmap=combined_cmap, overlays=overlays,\n",
    "                                          cmap_coef_range=None, cmap_p_vl_range=None, #ps['log_p_vls_cmap_range'],\n",
    "                                          title=var_name)\n",
    "            plt.savefig(save_folder_path / (combined_file_name + '.png'), facecolor=(0,0,0))\n",
    "            plt.close()\n",
    "                \n",
    "    if ps['gen_uber_movies']:\n",
    "        uber_file_name = var_name + '_' + ps['save_supp_str'] + '_coef_p_vls_comb'\n",
    "        uber_movie_path = save_folder_path / (uber_file_name + '.mp4')\n",
    "        comb_movies(movie_paths=[coef_movie_path, p_vl_movie_path, comb_movie_path], save_path=uber_movie_path)\n",
    "        \n",
    "        if not ps['gen_coef_movies']:\n",
    "            os.remove(coef_movie_path)\n",
    "        if not ps['gen_p_value_movies']:\n",
    "            os.remove(p_vl_movie_path)\n",
    "        if not ps['gen_combined_movies']:\n",
    "            os.remove(comb_movie_path)\n",
    "                \n",
    "    print('Done with making images for variable: ' + var_name)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = np.asarray([[0, 1], [2, 3]])\n",
    "t1 = 4 + np.asarray([[0, 1], [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.stack([t0, t1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.flipud(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [5, 7]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
