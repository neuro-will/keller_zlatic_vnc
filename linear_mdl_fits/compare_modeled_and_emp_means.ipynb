{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate means from raw data (e.g., the mean for all transitions from quite to forward) but we also fit our linear models, predict activity from these models and then compute the same means for the predicted activity.  We want to compare and make sure these are not too different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from janelia_core.stats.regression import grouped_linear_regression_boot_strap\n",
    "from janelia_core.stats.regression import visualize_boot_strap_results\n",
    "\n",
    "from keller_zlatic_vnc.linear_modeling import one_hot_from_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'/Users/williambishop/Desktop/extracted_dff/A00c'\n",
    "\n",
    "data_file = 'A00c_activity.pkl'\n",
    "\n",
    "# Specify variables that we predict from\n",
    "beh_before = ['Q', 'F', 'B']\n",
    "beh_after = ['Q', 'F', 'B']\n",
    "enc_beh_interactions = True\n",
    "enc_subjects = False\n",
    "closure = True # True if the only events we consider must start with a before_beh \n",
    "               # behavior and end with an beh_after behavior\n",
    "\n",
    "# Determine how we will display results\n",
    "font_size = 15\n",
    "\n",
    "# Determine what type of manipulation events we look at\n",
    "manip_type = 'A4' # 'both', 'A4' or 'A9'\n",
    "\n",
    "# Determine if we use training predictions or cross-valided predictions\n",
    "pred_type = 'cv' # 'train' or 'cv'\n",
    "\n",
    "\n",
    "if False:\n",
    "    # Transitions we want to compute averages for: This section is to reproduce Nadine's figures\n",
    "    transitions = [('F', 'F'), \n",
    "                   ('B', 'F'), \n",
    "                   ('Q', 'F'), \n",
    "                   ('B', 'B'), \n",
    "                   ('Q', 'Q')]\n",
    "\n",
    "    # Colors for plotting each transition for A00c\n",
    "    clrs = np.asarray([[28, 76, 124], \n",
    "                      [206, 222, 245],\n",
    "                      [0, 0, 0], \n",
    "                      [107, 227, 207], \n",
    "                      [213, 213, 213]])/256\n",
    "\n",
    "    # Colors for plotting each transition for handle\n",
    "    #clrs = np.asarray([[48, 111, 29], \n",
    "    #                  [83, 173, 50],\n",
    "    #                  [0, 0, 0], \n",
    "    #                  [191, 190, 59], \n",
    "    #                  [146, 146, 146]])/256\n",
    "else:\n",
    "    # Transitions we want to compute averages for: This is for squaring results with linear model results\n",
    "    transitions = [('F', 'F'), \n",
    "                   ('B', 'F'), \n",
    "                   ('Q', 'F'),\n",
    "                   ('F', 'B'),\n",
    "                   ('B', 'B'),\n",
    "                   ('Q', 'B'),\n",
    "                   ('F', 'Q'),\n",
    "                   ('B', 'Q'),\n",
    "                   ('Q', 'Q')]\n",
    "    \n",
    "    cmap = plt.get_cmap('Dark2')\n",
    "    clrs = cmap(np.arange(0, 10))[:,0:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(data_dir) / data_file\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down select to only the manipulation events we want to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing only A4 manipulation events.\n"
     ]
    }
   ],
   "source": [
    "if manip_type == 'A4':\n",
    "    print('Analyzing only A4 manipulation events.')\n",
    "    data = data[data['man_tgt'] == 'A4']\n",
    "elif manip_type == 'A9':\n",
    "    print('Analyzing only A9 manipulation events.')\n",
    "    data = data[data['man_tgt'] == 'A9']\n",
    "else:\n",
    "    print('Analyzing all manipulation events.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce closure if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enforcing closure.\n"
     ]
    }
   ],
   "source": [
    "if closure:\n",
    "    print('Enforcing closure.')\n",
    "    before_closure = np.asarray([b in set(beh_before) for b in data['beh_before']], \n",
    "                                dtype=bool)\n",
    "    after_closure = np.asarray([b in set(beh_after) for b in data['beh_after']], \n",
    "                                dtype=bool)\n",
    "    closure = np.logical_and(before_closure, after_closure)\n",
    "    \n",
    "    data = data[closure]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of rows of data that have no behavior of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_ignore = np.asarray([b not in set(beh_before) for b in data['beh_before']], \n",
    "                                dtype=bool)\n",
    "after_ignore = np.asarray([b not in set(beh_after) for b in data['beh_after']], \n",
    "                                dtype=bool)\n",
    "\n",
    "ignore_rows = np.logical_and(before_ignore, after_ignore)\n",
    "\n",
    "data = data[np.logical_not(ignore_rows)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get groups of data (a group corresponds to each subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = data['subject_id'].unique()\n",
    "g = np.zeros(len(data))\n",
    "for u_i, u_id in enumerate(unique_ids):\n",
    "    g[data['subject_id'] == u_id] = u_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out $\\Delta F / F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_before = data['dff_before'].to_numpy()\n",
    "dff_after = data['dff_after'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we fit linear models with user specified options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data, one_hot_vars = one_hot_from_table(data, \n",
    "                                                beh_before=beh_before, \n",
    "                                                beh_after=beh_after,\n",
    "                                                enc_subjects=enc_subjects, \n",
    "                                                enc_beh_interactions=enc_beh_interactions)\n",
    "if not enc_subjects:\n",
    "    one_hot_vars.append('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = one_hot_data.shape[0]\n",
    "\n",
    "if not enc_subjects:\n",
    "    one_hot_data_supp = np.concatenate([one_hot_data, np.ones([n_rows, 1])], axis=1)\n",
    "else:\n",
    "    one_hot_data_supp = one_hot_data\n",
    "\n",
    "if pred_type == 'train':\n",
    "    before_reg_rs, before_mdl = grouped_linear_regression_boot_strap(x=one_hot_data, \n",
    "                                                  y=dff_before, \n",
    "                                                  g=g, \n",
    "                                                  n_bs_smps=0, \n",
    "                                                  include_mean=(not enc_subjects))\n",
    "    after_reg_rs, after_mdl = grouped_linear_regression_boot_strap(x=one_hot_data, \n",
    "                                                   y=dff_after, \n",
    "                                                   g=g, \n",
    "                                                   n_bs_smps=0, \n",
    "                                                   include_mean=(not enc_subjects))\n",
    "    \n",
    "    dff_pred_before = np.sum(one_hot_data_supp*before_mdl, axis=1)\n",
    "    dff_pred_after = np.sum(one_hot_data_supp*after_mdl, axis=1)\n",
    "else:\n",
    "    dff_pred_before = np.zeros(n_rows)\n",
    "    dff_pred_after = np.zeros(n_rows)\n",
    "    dff_true_before = np.zeros(n_rows)\n",
    "    dff_true_after = np.zeros(n_rows)\n",
    "    \n",
    "    for r_i in range(n_rows):\n",
    "        test_inds = np.zeros(n_rows, dtype=np.bool)\n",
    "        test_inds[r_i] = True\n",
    "        train_inds = np.logical_not(test_inds)\n",
    "    \n",
    "        train_dff_before = dff_before[train_inds]\n",
    "        train_dff_after = dff_after[train_inds]\n",
    "        train_one_hot_data = one_hot_data[train_inds, :]\n",
    "    \n",
    "\n",
    "        test_one_hot_data_supp = one_hot_data_supp[test_inds, :]\n",
    "    \n",
    "        _, before_mdl = grouped_linear_regression_boot_strap(y=train_dff_before, \n",
    "                                                             x=train_one_hot_data,\n",
    "                                                             g=np.ones(len(train_dff_before)),\n",
    "                                                             n_bs_smps=0,\n",
    "                                                             include_mean=not enc_subjects)\n",
    "    \n",
    "        _, after_mdl = grouped_linear_regression_boot_strap(y=train_dff_after, \n",
    "                                                            x=train_one_hot_data,\n",
    "                                                            g=np.ones(len(train_dff_after)),\n",
    "                                                            n_bs_smps=0,\n",
    "                                                            include_mean=not enc_subjects)\n",
    "        \n",
    "        dff_pred_before[r_i] = np.sum(test_one_hot_data_supp*before_mdl)\n",
    "        dff_pred_after[r_i] = np.sum(test_one_hot_data_supp*after_mdl)\n",
    "        dff_true_before[r_i] = dff_before[test_inds]\n",
    "        dff_true_after[r_i] = dff_after[test_inds]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate transition means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_transition_means(activity, before_beh, after_beh, transitions):\n",
    "    n_transitions = len(transitions)\n",
    "    means = np.zeros(n_transitions)\n",
    "    for t_i, tran in enumerate(transitions):\n",
    "        before_inds = before_beh == tran[0]\n",
    "        after_inds = after_beh == tran[1]\n",
    "        keep_inds = np.logical_and(before_inds, after_inds)\n",
    "        means[t_i] = np.mean(activity[keep_inds])\n",
    "    \n",
    "    return means\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/keller_zlatic_vnc/lib/python3.7/site-packages/numpy-1.17.2-py3.7-macosx-10.7-x86_64.egg/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/envs/keller_zlatic_vnc/lib/python3.7/site-packages/numpy-1.17.2-py3.7-macosx-10.7-x86_64.egg/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "emp_before_means= calc_transition_means(dff_before, data['beh_before'].to_numpy(), \n",
    "                                        data['beh_after'].to_numpy(), transitions)\n",
    "\n",
    "emp_after_means= calc_transition_means(dff_after, data['beh_before'].to_numpy(), \n",
    "                                       data['beh_after'].to_numpy(), transitions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_before_means= calc_transition_means(dff_pred_before, data['beh_before'].to_numpy(), \n",
    "                                        data['beh_after'].to_numpy(), transitions)\n",
    "\n",
    "pred_after_means= calc_transition_means(dff_pred_after, data['beh_before'].to_numpy(), \n",
    "                                       data['beh_after'].to_numpy(), transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_means(emp_means, pred_means, clrs, transitions, title_str, ax=None, font_size=10):\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.axes()\n",
    "     \n",
    "    n_means = len(emp_means)\n",
    "    for mn_i in range(n_means):\n",
    "        e_mn = emp_means[mn_i]\n",
    "        p_mn = pred_means[mn_i]\n",
    "        \n",
    "        e_clr = np.ones(4)\n",
    "        e_clr[0:3] = clrs[mn_i, :]\n",
    "        plt.bar(2*mn_i, e_mn, color=e_clr)\n",
    "        \n",
    "        p_clr = .6*np.ones(4)\n",
    "        p_clr[0:3] = clrs[mn_i, :]\n",
    "        plt.bar(2*mn_i + 1, p_mn, color=p_clr)\n",
    "        \n",
    "    # Label x-axis\n",
    "    trans_strs = [t_1 + t_2 for t_1, t_2 in transitions]\n",
    "    first_str = trans_strs[0]\n",
    "    trans_strs[0] = first_str + ' emp'\n",
    "    trans_strs.insert(1, first_str + ' mdl')\n",
    "    x_ticks = [0, 1.0]\n",
    "    tick_clrs = [clrs[0,:], clrs[0,:]]\n",
    "    for t_i in range(1, n_means):\n",
    "        x_ticks.append(2*t_i)\n",
    "        tick_clrs.append(clrs[t_i,:])\n",
    "    plt.xticks(x_ticks, trans_strs, rotation=-90)\n",
    "\n",
    "    #Set colors of x-axix labels\n",
    "    for var_i, x_lbl in enumerate(ax.get_xticklabels()):\n",
    "        x_lbl.set_color(tick_clrs[var_i])\n",
    "        \n",
    "    ph = plt.xlabel('Transition Type', fontsize=font_size)\n",
    "    ph = plt.ylabel('Average $\\Delta F$ / F', fontsize=font_size)\n",
    "    ax.tick_params(axis=\"x\", labelsize=font_size)\n",
    "    ax.tick_params(axis=\"y\", labelsize=font_size)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.title(title_str, fontsize=font_size)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(6, 5)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_means(emp_means=emp_before_means, \n",
    "           pred_means=pred_before_means, \n",
    "           clrs=clrs, \n",
    "           transitions=transitions, \n",
    "           title_str = '$\\Delta F / F$ Before Perturbation',\n",
    "           font_size=font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_means(emp_means=emp_after_means, \n",
    "           pred_means=pred_after_means, \n",
    "           clrs=clrs, \n",
    "           transitions=transitions, \n",
    "           title_str = '$\\Delta F / F$ After Perturbation',\n",
    "           font_size=font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at predictions for individual events and neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$\\\\Delta F /F$ After Perturbation')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(dff_true_before, 'ro')\n",
    "plt.plot(dff_pred_before, 'b.')\n",
    "plt.title('$\\Delta F /F$ Before Perturbation')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dff_true_after, 'ro')\n",
    "plt.plot(dff_pred_after, 'b.')\n",
    "plt.title('$\\Delta F /F$ After Perturbation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
