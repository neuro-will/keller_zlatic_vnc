{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for different types of dependence, referencing to a single behavior.  The purpose of this notebook is to serve as a development location for the python script with the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "from keller_zlatic_vnc.data_processing import count_unique_subjs_per_transition\n",
    "from keller_zlatic_vnc.data_processing import extract_transitions\n",
    "from keller_zlatic_vnc.data_processing import generate_transition_dff_table\n",
    "from keller_zlatic_vnc.data_processing import read_raw_transitions_from_excel\n",
    "from keller_zlatic_vnc.data_processing import recode_beh\n",
    "from keller_zlatic_vnc.linear_modeling import one_hot_from_table\n",
    "from keller_zlatic_vnc.linear_modeling import order_and_color_interaction_terms\n",
    "from keller_zlatic_vnc.linear_modeling import reference_one_hot_to_beh\n",
    "\n",
    "\n",
    "from janelia_core.stats.regression import grouped_linear_regression_ols_estimator\n",
    "from janelia_core.stats.regression import grouped_linear_regression_acm_stats\n",
    "from janelia_core.stats.regression import visualize_coefficient_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we specify the location of the data\n",
    "\n",
    "data_folder = r'A:\\projects\\keller_vnc\\data\\extracted_dff_v2'\n",
    "transition_file = 'transition_list.xlsx'\n",
    "\n",
    "a00c_a4_act_data_file = 'A00c_activity_A4.mat'\n",
    "a00c_a9_act_data_file = 'A00c_activity_A9.mat'\n",
    "\n",
    "basin_a4_act_data_file = 'Basin_activity_A4.mat'\n",
    "basin_a9_act_data_file = 'Basin_activity_A9.mat'\n",
    "\n",
    "handle_a4_act_data_file = 'Handle_activity_A4.mat'\n",
    "handle_a9_act_data_file = 'Handle_activity_A9.mat'\n",
    "\n",
    "# =====================================================================\n",
    "# Here we specify the type of testing we will do.  Options are:\n",
    "#\n",
    "#   state_dependence - tests if dff after manipulation is sensitive to behavior before\n",
    "#   prediction_dependence - tests if dff before manipulation is sensitive to behavior after\n",
    "#   decision_dependence - tests if dff during manipulation is sensitive to behavior after\n",
    "#   before_reporting - tests if dff before manipulation is sensitive to behavior before\n",
    "#   after_reporting - tests if dff after manipulation is sensitive to behavior after\n",
    "#\n",
    "test_type = 'state_dependence'\n",
    "\n",
    "# =====================================================================\n",
    "# Here, we specify how we want to filter the data when fitting models.  \n",
    "\n",
    "# Cell types are tuples of form (cell type, list of cell ids).  In place of a list of cell ids, the string 'all'\n",
    "# indicates we are using all cell ids\n",
    "cell_type = ('handle', 'all')\n",
    "\n",
    "manip_type = 'A4+A9'#'A4', 'A9', 'A4+A9']\n",
    "cut_off_time = 3.656#, 9.0034]\n",
    "\n",
    "# Min number of subjects which must display a test behavior to include it in testing\n",
    "min_n_subjects_per_beh = 3\n",
    "\n",
    "# ======================================================================================================================\n",
    "# Here we specify the remaining parameters, common to all analyses\n",
    "\n",
    "# The behavior we use for reference\n",
    "beh_ref = 'Q'\n",
    "\n",
    "# Alpha value for forming confidence intervals and testing for significance\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trans = read_raw_transitions_from_excel(pathlib.Path(data_folder) / transition_file)\n",
    "\n",
    "# Recode behavioral annotations\n",
    "raw_trans = recode_beh(raw_trans, 'beh_before')\n",
    "raw_trans = recode_beh(raw_trans, 'beh_after')\n",
    "\n",
    "# Read in neural activity\n",
    "if cell_type[0] == 'a00c':\n",
    "    a4_act_file = a00c_a4_act_data_file\n",
    "    a9_act_file = a00c_a9_act_data_file\n",
    "elif cell_type[0] == 'basin':\n",
    "    a4_act_file = basin_a4_act_data_file\n",
    "    a9_act_file = basin_a9_act_data_file\n",
    "elif cell_type[0] == 'handle':\n",
    "    a4_act_file = handle_a4_act_data_file\n",
    "    a9_act_file = handle_a9_act_data_file\n",
    "else:\n",
    "    raise (ValueError('The cell type ' + cell_type + ' is not recogonized.'))\n",
    "\n",
    "a4_act = scipy.io.loadmat(pathlib.Path(data_folder) / a4_act_file, squeeze_me=True)\n",
    "a9_act = scipy.io.loadmat(pathlib.Path(data_folder) / a9_act_file, squeeze_me=True)\n",
    "\n",
    "# Correct mistake in labeling if we need to\n",
    "if cell_type[0] == 'basin' or cell_type[0] == 'handle':\n",
    "    ind = np.argwhere(a4_act['newTransitions'] == '0824L2CL')[1][0]\n",
    "    a4_act['newTransitions'][ind] = '0824L2-2CL'\n",
    "    \n",
    "# Extract transitions\n",
    "trans, _ = extract_transitions(raw_trans, cut_off_time)\n",
    "\n",
    "# Generate table of data\n",
    "a4table = generate_transition_dff_table(act_data=a4_act, trans=trans)\n",
    "a9table = generate_transition_dff_table(act_data=a9_act, trans=trans)\n",
    "\n",
    "# Put the tables together\n",
    "a4table['man_tgt'] = 'A4'\n",
    "a9table['man_tgt'] = 'A9'\n",
    "data = a4table.append(a9table, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down select for manipulation target if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if manip_type == 'A4':\n",
    "    data = data[data['man_tgt'] == 'A4']\n",
    "elif manip_type == 'A9':\n",
    "    data = data[data['man_tgt'] == 'A9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down select for cell id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids = cell_type[1]\n",
    "if isinstance(cell_ids, list):\n",
    "    keep_rows = data['cell_id'].apply(lambda x: x in set(cell_ids))\n",
    "    data = data[keep_rows]\n",
    "    print('Using only cell ids ' + str(cell_ids) + ', leaving ' + str(len(data)) + ' data rows.')\n",
    "else:\n",
    "    print('Using all cell ids, leaving ' + str(len(data)) + ' data rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which behaviors are present before and after the manipulation, removing behaviors we will test for if they are not present in enough subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_subj_cnts = count_unique_subjs_per_transition(data)\n",
    "if (test_type == 'state_dependence') or (test_type == 'before_reporting'):\n",
    "    after_beh_th = 0\n",
    "    before_beh_th = min_n_subjects_per_beh\n",
    "elif ((test_type == 'prediction_dependence') or (test_type == 'after_reporting') or \n",
    "      (test_type == 'decision_dependence')):\n",
    "    after_beh_th = min_n_subjects_per_beh\n",
    "    before_beh_th = 0\n",
    "else:\n",
    "    raise(ValueError('The test_type ' + test_type + ' is not recognized.'))\n",
    "\n",
    "after_beh_sum = trans_subj_cnts.sum()\n",
    "after_behs = [b for b in after_beh_sum[after_beh_sum >= after_beh_th].index]\n",
    "\n",
    "before_beh_sum = trans_subj_cnts.sum(1)\n",
    "before_behs = [b for b in before_beh_sum[before_beh_sum >= before_beh_th].index]\n",
    "\n",
    "before_keep_rows = data['beh_before'].apply(lambda x: x in set(before_behs))\n",
    "after_keep_rows = data['beh_after'].apply(lambda x: x in set(after_behs))\n",
    "data = data[before_keep_rows & after_keep_rows]\n",
    "\n",
    "# Update our list of before and after behaviors (since by removing rows, some of our control behaviors\n",
    "# may no longer be present\n",
    "new_trans_sub_cnts = count_unique_subjs_per_transition(data)\n",
    "new_after_beh_sum = new_trans_sub_cnts.sum()\n",
    "after_behs = [b for b in new_after_beh_sum[new_after_beh_sum > 0].index]\n",
    "new_before_beh_sum = new_trans_sub_cnts.sum(1)\n",
    "before_behs = [b for b in new_before_beh_sum[new_before_beh_sum>0].index]\n",
    "print('Using the following before behaviors: ' + str(before_behs))\n",
    "print('Using the following after behaviors: ' + str(after_behs))\n",
    "print(['Number of rows remaining in data: ' + str(len(data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out $\\Delta F/F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (test_type == 'state_dependence') or (test_type == 'after_reporting'):\n",
    "    dff = data['dff_after'].to_numpy()\n",
    "    print('Extracting dff after the manipulation.')\n",
    "elif (test_type == 'prediction_dependence') or (test_type == 'before_reporting'):\n",
    "    dff = data['dff_before'].to_numpy()\n",
    "    print('Extracting dff before the manipulation.')\n",
    "elif test_type == 'decision_dependence':\n",
    "    dff = data['dff_during'].to_numpy()\n",
    "    print('Extracting dff during the manipulation.')\n",
    "else:\n",
    "    raise(ValueError('The test_type ' + test_type + ' is not recognized.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find grouping of data by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find grouping of data by subject\n",
    "unique_ids = data['subject_id'].unique()\n",
    "g = np.zeros(len(data))\n",
    "for u_i, u_id in enumerate(unique_ids):\n",
    "    g[data['subject_id'] == u_id] = u_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model and calculate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_behs_ref = list(set(before_behs).difference(beh_ref))\n",
    "after_behs_ref = list(set(after_behs).difference(beh_ref))\n",
    "n_before_behs = len(before_behs_ref)\n",
    "n_after_behs = len(after_behs_ref)\n",
    "\n",
    "one_hot_data_ref, one_hot_vars_ref = one_hot_from_table(data, beh_before=before_behs_ref, beh_after=after_behs_ref)\n",
    "one_hot_data_ref = np.concatenate([one_hot_data_ref, np.ones([one_hot_data_ref.shape[0], 1])], axis=1)\n",
    "one_hot_vars_ref = one_hot_vars_ref + ['ref']\n",
    "    \n",
    "_, v, _ = np.linalg.svd(one_hot_data_ref)\n",
    "if np.min(v) < .001:\n",
    "    raise (RuntimeError('regressors are nearly co-linear'))\n",
    "            \n",
    "beta, acm, n_gprs = grouped_linear_regression_ols_estimator(x=one_hot_data_ref, y=dff, g=g)\n",
    "stats = grouped_linear_regression_acm_stats(beta=beta, acm=acm, n_grps=n_gprs, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out the stats for our variables we are testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (test_type == 'state_dependence') or (test_type == 'before_reporting'):\n",
    "    test_behs = before_behs_ref\n",
    "    test_betas = beta[0:n_before_behs]\n",
    "    test_c_ints = stats['c_ints'][:, 0:n_before_behs]\n",
    "    test_sig = stats['non_zero'][0:n_before_behs]\n",
    "elif ((test_type == 'prediction_dependence') or (test_type == 'after_reporting') or \n",
    "      (test_type == 'decision_dependence')):\n",
    "    test_behs = after_behs_ref\n",
    "    test_betas = beta[n_before_behs:n_before_behs+n_after_behs]\n",
    "    test_c_ints = stats['c_ints'][:, n_before_behs:n_before_behs+n_after_behs]\n",
    "    test_sig = stats['non_zero'][n_before_behs:n_before_behs+n_after_behs]\n",
    "else:\n",
    "    raise(ValueError('The test_type ' + test_type + ' is not recognized.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficient_stats(var_strs=test_behs, theta=test_betas, c_ints=test_c_ints, sig=test_sig, x_axis_rot=0)\n",
    "plt.ylabel('$\\Delta F / F$')\n",
    "plt.xlabel('Behavior')\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
