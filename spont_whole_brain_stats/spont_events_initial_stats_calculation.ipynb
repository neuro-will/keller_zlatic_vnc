{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook for generating initial statistics across the whole brain for the spontaneous events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from janelia_core.dataprocessing.dataset import ROIDataset\n",
    "from janelia_core.stats.regression import grouped_linear_regression_acm_stats\n",
    "from janelia_core.stats.regression import grouped_linear_regression_ols_estimator\n",
    "\n",
    "from keller_zlatic_vnc.data_processing import count_unique_subjs_per_transition\n",
    "from keller_zlatic_vnc.data_processing import generate_standard_id_for_full_annots\n",
    "from keller_zlatic_vnc.data_processing import generate_standard_id_for_volume\n",
    "from keller_zlatic_vnc.data_processing import get_basic_clean_annotations_from_full\n",
    "from keller_zlatic_vnc.data_processing import read_full_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parmaeters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = dict()\n",
    "\n",
    "# Folders containing a4 and a9 annotation data\n",
    "ps['a4_annot_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\full_annotations\\behavior_csv_cl_A4'\n",
    "ps['a9_annot_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\full_annotations\\behavior_csv_cl_A9'\n",
    "ps['spont_only_annot_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\full_annotations\\spontaneous_only_annotations'\n",
    "\n",
    "# File containing locations to registered volumes\n",
    "ps['volume_loc_file'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\data\\experiment_data_locations.xlsx'\n",
    "\n",
    "# List subjects we do not want to include in the analysis\n",
    "ps['exclude_subjs'] = set(['CW_17-11-06-L2'])\n",
    "\n",
    "# Specify the threshold we use (in number of stacks) to determine when a quiet transition has occured\n",
    "ps['q_th'] = 4\n",
    "\n",
    "# Subfolder containing the dataset for each subject\n",
    "ps['dataset_folder'] = 'extracted'\n",
    "\n",
    "# Base folder where datasets are stored \n",
    "ps['dataset_base_folder'] =r'K:\\\\SV4'\n",
    "\n",
    "# Data to calculate Delta F/F for in each dataset\n",
    "ps['f_ts_str'] = 'f_1_5_5'\n",
    "ps['bl_ts_str'] = 'bl_1_5_5_long'\n",
    "\n",
    "# Parameters for calculating dff\n",
    "ps['background'] = 100\n",
    "ps['ep'] = 20\n",
    "\n",
    "# Min number of subjects we must observe a transition in for us to analyze it\n",
    "min_n_subjs = 10\n",
    "\n",
    "# Alpha value for thresholding p-values when calculating stats\n",
    "ps['alpha'] = .05\n",
    "\n",
    "# Specify the window we pull dff from\n",
    "ps['window_type'] = 'start_locked' #'whole_event' 'start_locked'\n",
    "\n",
    "# If we are using a window locked to event start or stop, we give the relative offset and window length here\n",
    "ps['window_offset'] = -18\n",
    "ps['window_length'] = 15\n",
    "\n",
    "# Specify if we only consider events where the extracted dff window is entirely contained within the event\n",
    "ps['enforce_contained_events'] = False\n",
    "\n",
    "# True if we want to pool preceeding behaviors\n",
    "ps['pool_preceeding_behaviors'] = False\n",
    " \n",
    "# Specify where we save results\n",
    "ps['save_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\whole_brain_spont_stats'\n",
    "ps['save_name'] = 'spont_1_5_5_long_bl_co_4_start_locked_neg18_15.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all subjects we can analyze\n",
    "\n",
    "These are those we have registered volumes for and annotations and they are not in the excluded subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all annotation files and the subjects they correspond to\n",
    "annot_file_paths = (glob.glob(str(Path(ps['a4_annot_folder']) / '*.csv')) + \n",
    "                    glob.glob(str(Path(ps['a9_annot_folder']) / '*.csv')) +\n",
    "                    glob.glob(str(Path(ps['spont_only_annot_folder']) / '*.csv')))\n",
    "annot_file_names = [Path(p).name for p in annot_file_paths]\n",
    "annot_subjs = [generate_standard_id_for_full_annots(fn) for fn in annot_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in location of all registered volumes\n",
    "def c_fcn(str):\n",
    "    return str.replace(\"'\", \"\")\n",
    "converters = {0:c_fcn, 1:c_fcn}\n",
    "\n",
    "volume_locs = pd.read_excel(ps['volume_loc_file'], header=1, usecols=[1, 2], converters=converters)\n",
    "volume_subjs = [generate_standard_id_for_volume(volume_locs.loc[i,'Main folder'], \n",
    "                                                       volume_locs.loc[i,'Subfolder'])  for i in volume_locs.index]\n",
    "volume_inds = [i for i in volume_locs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update name of one of the volume subjects to match the annotations (this is only needed for one subject)\n",
    "m_ind = np.argwhere(np.asarray(volume_subjs) == 'CW_17-11-03-L6')[0][0]\n",
    "volume_subjs[m_ind] = 'CW_17-11-03-L6-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_subjs = set(volume_subjs).intersection(set(annot_subjs))\n",
    "analyze_subjs = analyze_subjs - set(ps['exclude_subjs'])\n",
    "analyze_subjs = list(np.sort(np.asarray(list(analyze_subjs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each subject we analyze, determine where it's annotation and volume data is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict = dict()\n",
    "for s_id in analyze_subjs:\n",
    "    volume_i = np.argwhere(np.asarray(volume_subjs) == s_id)[0][0]\n",
    "    annot_i = np.argwhere(np.asarray(annot_subjs) == s_id)[0][0]\n",
    "    subject_dict[s_id] = {'volume_main_folder': volume_locs.loc[volume_inds[volume_i], 'Main folder'],\n",
    "                          'volume_sub_folder': volume_locs.loc[volume_inds[volume_i], 'Subfolder'],\n",
    "                          'annot_file': annot_file_paths[annot_i]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the annotation data for all subjects we analyze\n",
    "\n",
    "We also generate cleaned and supplemented annotations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for s_id, d in subject_dict.items():\n",
    "    tbl = read_full_annotations(d['annot_file'])\n",
    "    tbl['subject_id'] = s_id\n",
    "    annotations.append(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = [get_basic_clean_annotations_from_full(annot) for annot in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.concat(annotations, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now threshold transitions to determine when events were preceeded or succeeded by quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.loc[(annotations['start'] - annotations['beh_before_end']) > ps['q_th'], 'beh_before'] = 'Q'\n",
    "annotations.loc[(annotations['beh_after_start'] - annotations['end']) > ps['q_th'], 'beh_after'] = 'Q'\n",
    "\n",
    "annotations.drop(['beh_before_start', 'beh_before_end', 'beh_after_start', 'beh_after_end'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool preceeding behaviors into one (G)rouped label if requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ps['pool_preceeding_behaviors']:\n",
    "    annotations['beh_before'] = 'G'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we read in the $\\frac{\\Delta F}{F}$ data for all subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dff(f, b, background=ps['background'], ep=ps['ep']):\n",
    "    return (f-b)/(b-background+ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_dff(x, start, stop):\n",
    "\n",
    "    if ps['window_type'] == 'whole_event':\n",
    "        take_slice = slice(start, stop)\n",
    "        starts_within_event = True\n",
    "        stops_within_event = True\n",
    "    elif ps['window_type'] == 'start_locked':\n",
    "        start_offset = start + ps['window_offset']\n",
    "        stop_offset = start_offset + ps['window_length']\n",
    "        take_slice = slice(start_offset, stop_offset)\n",
    "        starts_within_event = ps['window_offset'] >= 0\n",
    "        stops_within_event = (stop >= stop_offset) and (start <= stop_offset)\n",
    "    else:\n",
    "        raise(ValueError('The window_type is not recogonized.'))\n",
    "    \n",
    "    if (take_slice.start < 0) or (take_slice.stop > x.shape[0]):\n",
    "        mn_vls = np.nan\n",
    "    else:\n",
    "        mn_vls = np.mean(x[take_slice, :], axis=0)\n",
    "    \n",
    "    return mn_vls, starts_within_event, stops_within_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering neural data for subject CW_17-08-23-L1\n",
      "Gathering neural data for subject CW_17-08-23-L2\n",
      "Gathering neural data for subject CW_17-08-23-L4\n",
      "Gathering neural data for subject CW_17-08-24-L4\n",
      "Gathering neural data for subject CW_17-08-24-L5\n",
      "Gathering neural data for subject CW_17-08-26-L1\n",
      "Gathering neural data for subject CW_17-08-26-L2\n",
      "Gathering neural data for subject CW_17-08-26-L4\n",
      "Gathering neural data for subject CW_17-08-26-L5\n",
      "Gathering neural data for subject CW_17-08-26-L6\n",
      "Gathering neural data for subject CW_17-08-27-L1\n",
      "Gathering neural data for subject CW_17-08-27-L2\n",
      "Gathering neural data for subject CW_17-08-27-L4\n",
      "Gathering neural data for subject CW_17-08-27-L5\n",
      "Gathering neural data for subject CW_17-08-28-L1\n",
      "Gathering neural data for subject CW_17-08-28-L2\n",
      "Gathering neural data for subject CW_17-08-29-L2\n",
      "Gathering neural data for subject CW_17-08-31-L1\n",
      "Gathering neural data for subject CW_17-09-01-L1\n",
      "Gathering neural data for subject CW_17-09-01-L2\n",
      "Gathering neural data for subject CW_17-09-01-L3\n",
      "Gathering neural data for subject CW_17-11-02-L3\n",
      "Gathering neural data for subject CW_17-11-03-L1\n",
      "Gathering neural data for subject CW_17-11-03-L2\n",
      "Gathering neural data for subject CW_17-11-03-L3\n",
      "Gathering neural data for subject CW_17-11-03-L5\n",
      "Gathering neural data for subject CW_17-11-03-L6-2\n",
      "Gathering neural data for subject CW_17-11-03-L7\n",
      "Gathering neural data for subject CW_17-11-04-L1\n",
      "Gathering neural data for subject CW_17-11-04-L2\n",
      "Gathering neural data for subject CW_17-11-04-L3\n",
      "Gathering neural data for subject CW_17-11-04-L4\n",
      "Gathering neural data for subject CW_17-11-05-L6\n",
      "Gathering neural data for subject CW_17-11-05-L7\n",
      "Gathering neural data for subject CW_17-11-06-L1\n",
      "Gathering neural data for subject CW_17-11-06-L3\n",
      "Gathering neural data for subject CW_17-11-07-L3\n",
      "Gathering neural data for subject CW_17-11-07-L4\n",
      "Gathering neural data for subject CW_17-11-07-L5\n",
      "Gathering neural data for subject CW_17-11-08-L1\n",
      "Gathering neural data for subject CW_17-11-08-L2\n",
      "Gathering neural data for subject CW_17-11-08-L3\n",
      "Gathering neural data for subject CW_17-11-26-L1\n",
      "Gathering neural data for subject CW_17-11-26-L2\n",
      "Gathering neural data for subject CW_17-11-26-L3\n",
      "Gathering neural data for subject CW_17-11-26-L4\n",
      "Gathering neural data for subject CW_17-11-26-L5\n",
      "Gathering neural data for subject CW_17-11-27-L1\n",
      "Gathering neural data for subject CW_17-11-27-L2\n",
      "Gathering neural data for subject CW_17-11-27-L3\n",
      "Gathering neural data for subject CW_17-11-27-L4\n",
      "Gathering neural data for subject CW_17-11-27-L5\n",
      "Gathering neural data for subject CW_17-11-28-L2\n",
      "Gathering neural data for subject CW_17-11-28-L4\n",
      "Gathering neural data for subject CW_17-11-28-L6\n",
      "Gathering neural data for subject CW_17-11-29-L1\n",
      "Gathering neural data for subject CW_17-11-29-L2\n",
      "Gathering neural data for subject CW_17-11-29-L3\n",
      "Gathering neural data for subject CW_17-11-29-L4\n",
      "Gathering neural data for subject CW_17-11-29-L5\n",
      "Gathering neural data for subject CW_17-11-29-L6\n",
      "Gathering neural data for subject CW_17-11-30-L2\n",
      "Gathering neural data for subject CW_17-12-11-L3\n"
     ]
    }
   ],
   "source": [
    "extracted_dff = dict()\n",
    "for s_id in analyze_subjs:\n",
    "    print('Gathering neural data for subject ' + s_id)\n",
    "    \n",
    "    # Load the dataset for this subject\n",
    "    data_main_folder = subject_dict[s_id]['volume_main_folder']\n",
    "    data_sub_folder = subject_dict[s_id]['volume_sub_folder']\n",
    "    \n",
    "    dataset_path = (Path(ps['dataset_base_folder']) / data_main_folder / data_sub_folder / \n",
    "                        Path(ps['dataset_folder']) / '*.pkl')\n",
    "    dataset_file = glob.glob(str(dataset_path))[0]\n",
    "    \n",
    "    with open(dataset_file, 'rb') as f:\n",
    "            dataset = ROIDataset.from_dict(pickle.load(f))\n",
    "            \n",
    "    # Calculate dff\n",
    "    f=dataset.ts_data[ps['f_ts_str']]['vls'][:]\n",
    "    b=dataset.ts_data[ps['bl_ts_str']]['vls'][:]\n",
    "    dff = calc_dff(f=f, b=b)\n",
    "    \n",
    "    # Get the dff for each event\n",
    "    s_events = annotations[annotations['subject_id'] == s_id]\n",
    "    for index in s_events.index:\n",
    "        event_start = s_events['start'][index]\n",
    "        event_stop = s_events['end'][index] + 1 # +1 to account for inclusive indexing in table\n",
    "        extracted_dff[index] = calc_mean_dff(dff, event_start, event_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any events where the $\\Delta F /F$ window fell outside of the recorded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_keys = [k for k, vl in extracted_dff.items() if np.all(np.isnan(vl[0]))]\n",
    "for key in bad_keys:\n",
    "    del extracted_dff[key]\n",
    "    \n",
    "annotations.drop(bad_keys, axis='index', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put $\\Delta F/F$ into annotations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['dff'] = pd.Series({i:extracted_dff[i][0] for i in extracted_dff.keys()})\n",
    "annotations['starts_within_event'] = pd.Series({i:extracted_dff[i][1] for i in extracted_dff.keys()})\n",
    "annotations['stops_within_event'] = pd.Series({i:extracted_dff[i][2] for i in extracted_dff.keys()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce using only contained events if we need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ps['enforce_contained_events']:\n",
    "    keep_events = (annotations['starts_within_event'] == True) & (annotations['stops_within_event'] == True)\n",
    "    annotations = annotations[keep_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now see how many subjects we have for each transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjs_per_trans = count_unique_subjs_per_transition(annotations, before_str='beh_before', after_str='beh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>F</th>\n",
       "      <th>H</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>TL</th>\n",
       "      <th>TR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>H</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q</td>\n",
       "      <td>34.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TL</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TR</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       B     F     H     O     P    Q    TL    TR\n",
       "B    6.0   0.0  12.0   1.0   3.0  0.0  29.0  32.0\n",
       "F    0.0  48.0  10.0   0.0  37.0  0.0  15.0  22.0\n",
       "H    9.0   5.0   6.0   2.0   9.0  0.0  32.0  31.0\n",
       "O    1.0  17.0   2.0   1.0   7.0  0.0   1.0   5.0\n",
       "P    7.0  35.0  17.0   3.0   3.0  0.0  22.0  22.0\n",
       "Q   34.0  60.0  49.0  35.0  48.0  0.0  55.0  58.0\n",
       "TL  25.0  37.0  12.0   2.0  14.0  0.0   4.0  39.0\n",
       "TR  28.0  35.0  13.0   1.0  21.0  0.0  37.0   1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_subjs_per_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of transitions we observe in enough subjects to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_trans = [[(bb, ab) for ab in n_subjs_per_trans.loc[bb].index if n_subjs_per_trans[ab][bb] >= min_n_subjs] \n",
    "                for bb in n_subjs_per_trans.index]\n",
    "analyze_trans = list(itertools.chain(*analyze_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-select events in annotations to only those with transitions that we will analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_codes = [b[0] + b[1] for b in analyze_trans]\n",
    "annot_trans_codes = [annotations['beh_before'][i] + annotations['beh'][i] for i in annotations.index]\n",
    "keep_annots = np.asarray([True if code in keep_codes else False for code in annot_trans_codes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_annotations = annotations[keep_annots]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate our regressors and group indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = len(analyze_annotations)\n",
    "n_analyze_trans = len(analyze_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = analyze_annotations['subject_id'].unique()\n",
    "g = np.zeros(n_events)\n",
    "for u_i, u_id in enumerate(unique_ids):\n",
    "    g[analyze_annotations['subject_id'] == u_id] = u_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([n_events, n_analyze_trans])\n",
    "for row_i in range(n_events):\n",
    "    event_trans_code = analyze_annotations.iloc[row_i]['beh_before'] + analyze_annotations.iloc[row_i]['beh']\n",
    "    event_trans_col = np.argwhere(np.asarray(keep_codes) == event_trans_code)[0][0]\n",
    "    x[row_i, event_trans_col] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now actually calculate our statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = np.stack(analyze_annotations['dff'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for calculating stats\n",
    "\n",
    "def stats_f(x_i, y_i, g_i, alpha_i):\n",
    "    beta, acm, n_grps = grouped_linear_regression_ols_estimator(x=x_i, y=y_i, g=g_i)\n",
    "    stats = grouped_linear_regression_acm_stats(beta=beta, acm=acm, n_grps=n_grps, alpha=alpha_i)\n",
    "    stats['beta'] = beta\n",
    "    stats['acm'] = acm\n",
    "    stats['n_grps'] = n_grps\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rois = dff.shape[1]\n",
    "full_stats = [stats_f(x_i=x, y_i=dff[:, r_i], g_i=g, alpha_i=ps['alpha']) for r_i in range(n_rois)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now save our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = {'ps': ps, 'full_stats': full_stats, 'beh_trans': analyze_trans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(ps['save_folder']) / ps['save_name']\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(rs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
