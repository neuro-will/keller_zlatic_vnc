{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of basic statistical results, which give coefficients for individual transitions, we search for coefficients which are different than mean of all other coefficients. We do this for each coefficient and record the p-values.\n",
    "\n",
    "This will save results in a format that is conducive for working with existing plotting code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keller_zlatic_vnc.whole_brain.whole_brain_stat_functions import test_for_different_than_avg_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = dict()\n",
    "ps['save_folder'] = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\whole_brain_spont_stats'\n",
    "ps['basic_rs_file'] = 'spont_1_5_5_long_bl_co_4_start_locked_neg18_15.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the basic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(ps['save_folder']) / ps['basic_rs_file'], 'rb') as f:\n",
    "    basic_rs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_trans = basic_rs['beh_trans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for values different than \"other\" mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_diff_than_mean_vls(stats, beh_trans):\n",
    "    \"\"\" This is a helper function which calculates post-hoc statistics for each group.\n",
    "    \n",
    "    A group are all transitions that start with the same behavior. \n",
    "    \n",
    "    For a coefficient in each group, we calculate the p-value that it's value is not larger than the mean of all\n",
    "    other coefficients in the group. \n",
    "    \n",
    "    If there is only one transition in a group (e.g., for a given start behavior, we only have transitions into\n",
    "    a single end behavior, we also set the p-value of these coefficients to 1.)\n",
    "    \n",
    "    We return all p-values in a single vector, for ease of integration with plotting code, but it should be remembered\n",
    "    that coefficinets were compared within groups. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_coefs = len(beh_trans)\n",
    "    p_vls = np.zeros(n_coefs)\n",
    "    beta = np.zeros(n_coefs)\n",
    "    \n",
    "    unique_grp_behs = set([t[0] for t in beh_trans])\n",
    "    \n",
    "    # Process results for each group\n",
    "    for grp_b in unique_grp_behs:\n",
    "        keep_cols = np.asarray(np.argwhere([1 if b[0] == grp_b else 0 for b in beh_trans])).squeeze()\n",
    "\n",
    "        p_vls[keep_cols] = 1 # Initially set all p-values to this group to 1, we will set the p-value \n",
    "                             # for the largest coefficient in the code below, but do denote that the \n",
    "                             # coefficients which are not largest are not to be considered, we set their\n",
    "                             # p-values to 1. \n",
    "\n",
    "        if keep_cols.ndim > 0: # Means we have more than one coefficient\n",
    "            grp_beta = stats['beta'][keep_cols]\n",
    "            grp_acm = stats['acm'][np.ix_(keep_cols, keep_cols)]\n",
    "            n_grps = stats['n_grps']\n",
    "            # Note: alpha below is not important for this function, since we record p-values\n",
    "            grp_p_vls, _  = test_for_different_than_avg_beta(beta=grp_beta, acm=grp_acm, n_grps=n_grps, alpha=.05)\n",
    "            p_vls[keep_cols] = grp_p_vls\n",
    "            \n",
    "            n_grp_coefs = len(grp_beta)\n",
    "            new_grp_beta = np.zeros(n_grp_coefs)\n",
    "            for b_i in range(n_grp_coefs):\n",
    "                new_grp_beta[b_i] = grp_beta[b_i] - ((np.sum(grp_beta) - grp_beta[b_i])/(n_grp_coefs - 1))\n",
    "            \n",
    "            beta[keep_cols] = new_grp_beta\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # We don't need to do anything - because we already set all p_vls for this group to 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_stats = dict()\n",
    "    new_stats['beta'] = beta\n",
    "    new_stats['eq_mean_p'] = p_vls\n",
    "    \n",
    "    return new_stats\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_stats = [test_for_diff_than_mean_vls(s, basic_rs['beh_trans']) for s in basic_rs['full_stats']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now save our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = {'ps': ps, 'full_stats': all_mean_stats, 'beh_trans': basic_rs['beh_trans']}\n",
    "\n",
    "save_folder = ps['save_folder']\n",
    "save_name = ps['basic_rs_file'].split('.')[0] + '_mean_cmp_stats.pkl'\n",
    "\n",
    "save_path = Path(save_folder) / save_name\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(rs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a4_annot_folder': '\\\\\\\\dm11\\\\bishoplab\\\\projects\\\\keller_vnc\\\\data\\\\full_annotations\\\\behavior_csv_cl_A4',\n",
       " 'a9_annot_folder': '\\\\\\\\dm11\\\\bishoplab\\\\projects\\\\keller_vnc\\\\data\\\\full_annotations\\\\behavior_csv_cl_A9',\n",
       " 'spont_only_annot_folder': '\\\\\\\\dm11\\\\bishoplab\\\\projects\\\\keller_vnc\\\\data\\\\full_annotations\\\\spontaneous_only_annotations',\n",
       " 'volume_loc_file': '\\\\\\\\dm11\\\\bishoplab\\\\projects\\\\keller_vnc\\\\data\\\\experiment_data_locations.xlsx',\n",
       " 'exclude_subjs': {'CW_17-11-06-L2'},\n",
       " 'q_th': 4,\n",
       " 'dataset_folder': 'extracted',\n",
       " 'dataset_base_folder': 'K:\\\\\\\\SV4',\n",
       " 'f_ts_str': 'f_1_5_5',\n",
       " 'bl_ts_str': 'bl_1_5_5_long',\n",
       " 'background': 100,\n",
       " 'ep': 20,\n",
       " 'alpha': 0.05,\n",
       " 'window_type': 'start_locked',\n",
       " 'window_offset': 0,\n",
       " 'window_length': 6,\n",
       " 'enforce_contained_events': True,\n",
       " 'pool_preceeding_behaviors': True,\n",
       " 'save_folder': '\\\\\\\\dm11\\\\bishoplab\\\\projects\\\\keller_vnc\\\\results\\\\whole_brain_spont_stats',\n",
       " 'save_name': 'spont_2_10_10_long_bl_co_4_start_locked_0_6_ece_pre_pooled.pkl'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rs['ps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
