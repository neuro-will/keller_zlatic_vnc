{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to package one set of statistical results into a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from keller_zlatic_vnc.collections import form_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing produced maps\n",
    "image_folder = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\initial_single_subject_small_window_sweep\\ind_collections\\beh_stats_neg_3_3_turns_broken_out_mean_cmp_stats_images'\n",
    "\n",
    "# Give path to a file holding parameters used to extract fluorescece\n",
    "f_extraction_params_file = r'K:\\SV4\\CW_17-08-23\\L1-561nm-ROIMonitoring_20170823_145226.corrected\\extracted\\rois_1_5_5\\extraction_params.pkl'\n",
    "\n",
    "# Give path to a file holding parameters used to extract baselines\n",
    "baseline_calc_params_file = r'K:\\SV4\\CW_17-08-23\\L1-561nm-ROIMonitoring_20170823_145226.corrected\\extracted\\rois_1_5_5\\long_baseline_extract_params.pkl'\n",
    "\n",
    "# Give path to a file holding parameters for the initial model fitting\n",
    "mdl_fitting_params_file = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\initial_single_subject_small_window_sweep\\ind_collections\\beh_stats_neg_3_3_turns_broken_out.pkl'\n",
    "\n",
    "# Give path to a file holding parameters for calculating statistics when comparing means\n",
    "mean_cmp_params_file = r'\\\\dm11\\bishoplab\\projects\\keller_vnc\\results\\initial_single_subject_small_window_sweep\\ind_collections\\beh_stats_neg_3_3_turns_broken_out_mean_cmp_stats.pkl'\n",
    "\n",
    "# Path to folder collection should be created in\n",
    "tgt_folder = image_folder\n",
    "\n",
    "# List those who can be contacted with questions about the collection\n",
    "responsible = ['William Bishop <bishopw@hhmi.janelia.org>', 'Andrew Champion <andrew.champion@gmail.com>']\n",
    "\n",
    "# Provide a description of the collection. \n",
    "description = ('This is part of an initial analysis performed to generate a set of maps that can serve as a testbed for ' + \n",
    "               'integrating statistical maps with EM. This particular analysis contains results for a statistical analysis ' + \n",
    "               'of the single specimen for which we also have an EM volumen for, and we look for voxels which encode an ' + \n",
    "               'upcoming behavior.  This is only one analysis in a larger analysis in which we vary the location of the window ' + \n",
    "               'we analyze neural activity in.  Note that because the actual statistical results were performed before we ' + \n",
    "               'determined how we were going to record metadata for the collections, the GIT hashes in this metadata ' + \n",
    "               'are only approximate, as the exact hashes were not recorded at the time the statistical testing was done. ' + \n",
    "               'The key notebooks and scripts to run the statistical tests used to produce these maps are ' + \n",
    "               'spont_events_initial_stats_calculation.ipynb and find_vls_different_than_other_mean.py.  The script ' + \n",
    "               'make_spont_whole_brain_movies_and_images.py was then used to render the actual maps.')\n",
    "\n",
    "# List hashes identify commits in git for the different pieces of code used to produce these results\n",
    "git_hashes = {'janelia_core': '004754091f3e793b681987d72341185826f5de79', \n",
    "             'keller_zlatic_vnc': 'beda4ab71553e0a3693af0f37c853f5d2966fee2'}\n",
    "\n",
    "# List the parameters that should be included in the metadata file\n",
    "f_extraction_yaml_fields = {'voxel_size_per_dim': 'Number of voxels in each dimension of a supervoxel.'}\n",
    "\n",
    "baseline_calc_yaml_fields = {'window_length': 'Length of window used for baseline calculation.',\n",
    "                             'filter_start': 'Initial offset, relative to first data point, of window used for baseline calculations.', \n",
    "                             'write_offset': \"Offset between first point in window and the point the filtered output is assigned to.\", \n",
    "                             'p': 'The particular percentile used for percentile filtering.'}\n",
    "\n",
    "mdl_fitting_yaml_fields = {'q_th': 'The threshold in times points used for determining if a behavior is preceeded by quiet.', \n",
    "                           'enforce_contained_events': 'True if only events with behaviors falling entirely within the window of analyzed neural activity should be included in the data used for model fitting.',\n",
    "                           'pool_preceeding_behaviors': 'True if all preceeding behaviors should be pooled.', \n",
    "                           'pool_preceeding_turns': 'True if left and right preceeding turns should be pooled.',\n",
    "                           'pool_succeeding_turns': 'True if succeeding left and right turns should be pooled.',\n",
    "                           'clean_event_def': 'The criteria used for determing which events are clean, with respect to how they overlap other events, for inclusion in the analysis.',\n",
    "                           'behaviors': 'Filter applied so that only behaviors in this set are included in the analysis.',\n",
    "                           'min_n_subjs': 'The min number of subjects we need to observe a transition for in order to include it in the model.',\n",
    "                           'min_n_events': 'The min number of times we need to observe a transition (across all subejcts) to include it in the model.',\n",
    "                           'window_type': 'The method for determining the alignment of the window of neural activity relative to behavior.',\n",
    "                           'window_offset': 'The offset in time points of the start of the window of neural activity relative to behaivor.',\n",
    "                           'window_length': 'The length of the window in time points of neural activity analyzed.'\n",
    "                           }\n",
    "\n",
    "mean_cmp_yaml_fields = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pickle files containing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f_extraction_params_file, 'rb') as f:\n",
    "    f_extraction_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(baseline_calc_params_file, 'rb') as f:\n",
    "    baseline_calc_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mdl_fitting_params_file, 'rb') as f:\n",
    "    mdl_fitting_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mean_cmp_params_file, 'rb') as f:\n",
    "    mean_cmp_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the set of preceeding and succeeding behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preceding_behs = list(set(t[0] for t in mean_cmp_results['beh_trans']))\n",
    "preceding_behs.sort()\n",
    "suceeding_behs = list(set(t[1] for t in mean_cmp_results['beh_trans']))\n",
    "suceeding_behs.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'desc': 'f_extraction_params', \n",
    "          'for_saving': f_extraction_params, \n",
    "          'for_metadata': f_extraction_params['roi_extract_opts'], \n",
    "          'inc_params': f_extraction_yaml_fields}, \n",
    "          {'desc': 'baseline_calc_params', \n",
    "          'for_saving': baseline_calc_params, \n",
    "          'for_metadata': baseline_calc_params['baseline_calc_opts'], \n",
    "          'inc_params': baseline_calc_yaml_fields},\n",
    "          {'desc': 'mdl_fitting_params', \n",
    "           'for_saving': mdl_fitting_results['ps'], \n",
    "           'for_metadata': mdl_fitting_results['ps'], \n",
    "           'inc_params': mdl_fitting_yaml_fields},\n",
    "          {'desc': 'mean_cmp_params', \n",
    "           'for_saving': mean_cmp_results['ps'], \n",
    "           'for_metadata': mean_cmp_results['ps'], \n",
    "           'inc_params': mean_cmp_yaml_fields}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_collection(image_folder=image_folder, \n",
    "                tgt_folder=tgt_folder,\n",
    "                description=description,\n",
    "                responsible=responsible,\n",
    "                git_hashes=git_hashes,\n",
    "                preceding_behs=preceding_behs,\n",
    "                suceeding_behs=suceeding_behs,\n",
    "                params=params, \n",
    "                ignore_extensions=['.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
